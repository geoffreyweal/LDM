{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOc1Iq9R6mzVo3OyHOGCdpF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# **Literature Data Mining: A Guide for Automatically Downloading and Highlighting Literature on Mass**\n","\n","This workbook is designed to help you use programs developed for performing data mining on literature. \n","\n","This workbook uses the `ScrapPaper` program that were originally developed by M. R. Rafsanjani. See https://github.com/rafsanlab/ScrapPaper and https://doi.org/10.1101/2022.03.08.483427"],"metadata":{"id":"3q03g22xi14_"}},{"cell_type":"markdown","source":["## **Prelim 1: Download programs for data mining on literature**\n","\n","Before running code in this notebook, we need to install and download some python programs and scripts into Google Colab. \n","\n","**Click on the** <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/> **button below that is next to the**\n","<font color=\"black\" size=\"+2\">←</font><font color=\"red\" size=\"+1\"> **Click the play button to load our prerequisite files**</font> <font color=\"black\" size=\"\"> **message.**\n","\n","When you click the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/>, the python programs and scripts we need will be start downloading. \n","\n","**These programs and scripts will be downloaded onto the Google colab webpage, and will not be downloaded onto your computer**\n","\n","<font>"],"metadata":{"id":"qmefln0Sjwcy"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"j9mQ8Z0rgWFe","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1666417617633,"user_tz":-780,"elapsed":4330,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}},"outputId":"ed109989-26de-4f61-9c62-ab87b7972d0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------\n","Installing python programs\n","Completed installing python programs\n","--------------------------------\n","Downloading background python scripts from github\n","Completed downloading background python scripts from github\n","--------------------------------\n"]}],"source":["#@markdown <font color=\"black\" size=\"+2\">←</font><font color=\"red\" size=\"+1\"> **Click the play button to load our prerequisite files**</font>\n","\n","!echo --------------------------------\n","!echo Installing python programs\n","!pip install BeautifulSoup &> /dev/nul\n","!echo Completed installing python programs\n","!if [ -d LDM ]; then rm -Rf LDM; fi\n","!echo --------------------------------\n","!echo Downloading background python scripts from github\n","!git clone https://github.com/geoffreyweal/LDM &> /dev/nul\n","!echo Completed downloading background python scripts from github\n","!echo --------------------------------\n","\n","from LDM.Programs.LDM import LDM"]},{"cell_type":"markdown","source":["## **Prelim 2: How to use Google Colab**\n","\n","Google Colab notebooks are web-based notebooks that allow you to write notes in and write code for running python programs. Think of these notebooks like a Word document in Microsoft Office that also can run code.\n","\n","Lets run some code to print a message to the screen. To do this, hover your mouse over the line of code in the shaded boxes below and click on the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"25\"/>. This will run the python code below"],"metadata":{"id":"xCF9ZkoFjioT"}},{"cell_type":"code","source":["print('Lets start Literature Data Mining!!!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ0jeoyQnYHM","executionInfo":{"status":"ok","timestamp":1666417617634,"user_tz":-780,"elapsed":7,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}},"outputId":"e1fbc72d-a635-4f0a-e3f4-6f1977fa6282"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Lets start Literature Data Mining!!!\n"]}]},{"cell_type":"markdown","source":["# **Main Section: Literature Mining**\n","\n","We are now ready to do some data mining. Follow the instructions below:"],"metadata":{"id":"qfShZvHCrKEc"}},{"cell_type":"markdown","source":["## **1.What do you want to search?**"],"metadata":{"id":"-Eod6h0lsMed"}},{"cell_type":"code","source":["searches = ['Anna Garden', 'Clusters']"],"metadata":{"id":"Wvx5JQO_xAMT","executionInfo":{"status":"ok","timestamp":1666417617634,"user_tz":-780,"elapsed":5,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## **2. Run the Literature Data Mining Program**"],"metadata":{"id":"_RJ7DX2vxL4r"}},{"cell_type":"code","source":["LDM(searches)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"pac0ZsQyxTwE","executionInfo":{"status":"error","timestamp":1666417632817,"user_tz":-780,"elapsed":15188,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}},"outputId":"ad1f6210-84f9-4511-a448-777567faff9a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------\n","PRELIM STEP: GATHERING DATA ABOUT SEARCHES\n","\n","Gathering search data on: Anna Garden\n","Total page number: 44101\n","Total search results: 441000.\n","\n","Gathering search data on: Clusters\n","Total page number: 537001\n","Total search results: 5370000.\n","\n","------------------------------------------------\n","MAIN STEP: LITERATURE DATA MINING\n","\n","Looking at Search: Anna Garden; Page: 1\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-5800661f779a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLDM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/LDM/Programs/LDM.py\u001b[0m in \u001b[0;36mLDM\u001b[0;34m(searches)\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0;31m# 3.2: Scrap Google Scholar data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0mfinished_scrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterature_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrap_google_scholar_for_literature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_num_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                         \u001b[0mtitle_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliterature_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;31m# 3.3: Append URL to all_literature_results list if it is not already in the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"]}]}]}