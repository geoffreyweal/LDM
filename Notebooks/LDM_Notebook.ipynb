{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP3NYbwXJyQRSZJ0hyqieDU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# **Literature Data Mining: A Guide for Automatically Downloading and Highlighting Literature on Mass**\n","\n","This workbook is designed to help you use programs developed for performing data mining on literature. \n","\n","This workbook uses the `ScrapPaper` program that were originally developed by M. R. Rafsanjani. See https://github.com/rafsanlab/ScrapPaper and https://doi.org/10.1101/2022.03.08.483427"],"metadata":{"id":"3q03g22xi14_"}},{"cell_type":"markdown","source":["## **Prelim 1: Download programs for data mining on literature**\n","\n","Before running code in this notebook, we need to install and download some python programs and scripts into Google Colab. \n","\n","**Click on the** <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/> **button below that is next to the**\n","<font color=\"black\" size=\"+2\">←</font><font color=\"red\" size=\"+1\"> **Click the play button to load our prerequisite files**</font> <font color=\"black\" size=\"\"> **message.**\n","\n","When you click the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/>, the python programs and scripts we need will be start downloading. \n","\n","**These programs and scripts will be downloaded onto the Google colab webpage, and will not be downloaded onto your computer**\n","\n","<font>"],"metadata":{"id":"qmefln0Sjwcy"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"j9mQ8Z0rgWFe","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1666421053028,"user_tz":-780,"elapsed":3794,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}},"outputId":"ad4195a4-cd06-408a-9070-01c3c837eb0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------\n","Installing python programs\n","Completed installing python programs\n","--------------------------------\n","Downloading background python scripts from github\n","Completed downloading background python scripts from github\n","--------------------------------\n"]}],"source":["#@markdown <font color=\"black\" size=\"+2\">←</font><font color=\"red\" size=\"+1\"> **Click the play button to load our prerequisite files**</font>\n","\n","!echo --------------------------------\n","!echo Installing python programs\n","!pip install BeautifulSoup &> /dev/nul\n","!echo Completed installing python programs\n","!if [ -d LDM ]; then rm -Rf LDM; fi\n","!echo --------------------------------\n","!echo Downloading background python scripts from github\n","!git clone https://github.com/geoffreyweal/LDM &> /dev/nul\n","!echo Completed downloading background python scripts from github\n","!echo --------------------------------"]},{"cell_type":"markdown","source":["## **Prelim 2: How to use Google Colab**\n","\n","Google Colab notebooks are web-based notebooks that allow you to write notes in and write code for running python programs. Think of these notebooks like a Word document in Microsoft Office that also can run code.\n","\n","Lets run some code to print a message to the screen. To do this, hover your mouse over the line of code in the shaded boxes below and click on the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"25\"/>. This will run the python code below"],"metadata":{"id":"xCF9ZkoFjioT"}},{"cell_type":"code","source":["print('Lets start Literature Data Mining!!!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ0jeoyQnYHM","executionInfo":{"status":"ok","timestamp":1666421053029,"user_tz":-780,"elapsed":10,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}},"outputId":"1501c0e1-3f66-47c5-a9ac-5ef47af82475"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Lets start Literature Data Mining!!!\n"]}]},{"cell_type":"markdown","source":["# **Main Section: Literature Mining**\n","\n","We are now ready to do some data mining. Follow the instructions below:"],"metadata":{"id":"qfShZvHCrKEc"}},{"cell_type":"code","source":["from LDM.Programs.LDM import LDM"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"id":"68Bu4XPlbs5Q","executionInfo":{"status":"error","timestamp":1666421074490,"user_tz":-780,"elapsed":321,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}},"outputId":"aab4b1f9-6e2b-4c41-e2df-d696efeaf3ee"},"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/content/LDM/Programs/LDM.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mLDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_internet\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mget_data_about_google_scholar_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscrap_google_scholar_for_literature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mLDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_PDFs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mLDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauxiliary_methods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/LDM/Programs/download_PDFs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mHTMLParser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTMLParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'HTMLParser'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-406e1348ccc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLDM\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLDM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/LDM/Programs/LDM.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mLDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauxiliary_methods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0msearch_internet\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mget_data_about_google_scholar_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscrap_google_scholar_for_literature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdownload_PDFs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mauxiliary_methods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'search_internet'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["## **1.What do you want to search?**"],"metadata":{"id":"-Eod6h0lsMed"}},{"cell_type":"code","source":["searches = ['Anna Garden', 'Clusters']"],"metadata":{"id":"Wvx5JQO_xAMT","executionInfo":{"status":"aborted","timestamp":1666421053030,"user_tz":-780,"elapsed":7,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Run the Literature Data Mining Program**"],"metadata":{"id":"_RJ7DX2vxL4r"}},{"cell_type":"code","source":["LDM(searches)"],"metadata":{"id":"pac0ZsQyxTwE","executionInfo":{"status":"aborted","timestamp":1666421053030,"user_tz":-780,"elapsed":7,"user":{"displayName":"Geoffrey Weal","userId":"12161107421352445371"}}},"execution_count":null,"outputs":[]}]}